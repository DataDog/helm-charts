---
# Source: datadog/templates/agent-clusterchecks-pdb.yaml
apiVersion: "policy/v1"
kind: PodDisruptionBudget
metadata:
  name: datadog-clusterchecks
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: datadog-clusterchecks
---
# Source: datadog/templates/cluster-agent-pdb.yaml
apiVersion: "policy/v1"
kind: PodDisruptionBudget
metadata:
  name: datadog-cluster-agent
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: datadog-cluster-agent
---
# Source: datadog/templates/agent-clusterchecks-rbac.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
    app: "datadog"
    chart: "datadog-3.58.2"
    heritage: "Helm"
    release: "datadog"
  name: datadog-cluster-checks
  namespace: datadog-agent
---
# Source: datadog/templates/cluster-agent-rbac.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  labels:
    app: "datadog"
    chart: "datadog-3.58.2"
    heritage: "Helm"
    release: "datadog"
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-cluster-agent
  namespace: datadog-agent
---
# Source: datadog/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: datadog
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7" # end range $role := .Values.datadog.secretBackend.roles
---
# Source: datadog/templates/secret-cluster-agent-token.yaml
apiVersion: v1
kind: Secret
metadata:
  name: datadog-cluster-agent
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
type: Opaque
data:
  token: "TkNSTkV5UlJqdjhHV0NWcmduMmRBaWdqTUw2WmdsV2g="
---
# Source: datadog/templates/cluster-agent-confd-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datadog-cluster-agent-confd
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  annotations:
    checksum/confd-config: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
data:
  kubernetes_state_core.yaml.default: |-
    cluster_check: true
    init_config:
    instances:
      - collectors:
        - secrets
        - configmaps
        - nodes
        - pods
        - services
        - resourcequotas
        - replicationcontrollers
        - limitranges
        - persistentvolumeclaims
        - persistentvolumes
        - namespaces
        - endpoints
        - daemonsets
        - deployments
        - replicasets
        - statefulsets
        - cronjobs
        - jobs
        - horizontalpodautoscalers
        - poddisruptionbudgets
        - storageclasses
        - volumeattachments
        - ingresses
        skip_leader_election: true
        labels_as_tags:
          {}
        annotations_as_tags:
          {}
---
# Source: datadog/templates/install_info-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datadog-installinfo
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  annotations:
    checksum/install_info: 3c5d7a2732f453d72b241f37b74f59319bcbf51e387a8fc35dc47bc4a1a7a390
data:
  install_info: |
    ---
    install_method:
      tool: helm
      tool_version: Helm
      installer_version: datadog-3.58.2
---
# Source: datadog/templates/kpi-telemetry-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datadog-kpi-telemetry-configmap
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
data:
  install_id: "fd55046d-8dfc-47a6-9fb7-20088a93ea58"
  install_type: k8s_manual
  install_time: "1710950775"
---
# Source: datadog/templates/cluster-agent-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-cluster-agent
rules:
- apiGroups:
  - ""
  resources:
  - services
  - endpoints
  - pods
  - nodes
  - namespaces
  - componentstatuses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
  - create
- apiGroups: ["quota.openshift.io"]
  resources:
  - clusterresourcequotas
  verbs:
  - get
  - list
- apiGroups:
  - "autoscaling"
  resources:
  - horizontalpodautoscalers
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  resourceNames:
  - datadogtoken  # Kubernetes event collection state
  - datadogtoken  # Kept for backward compatibility with agent <7.37.0
  verbs:
  - get
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  resourceNames:
  - datadog-leader-election  # Leader election token
  - datadog-leader-election  # Kept for backward compatibility with agent <7.37.0
  verbs:
  - get
  - update
- apiGroups:
  - "coordination.k8s.io"
  resources:
  - leases
  resourceNames:
  - datadog-leader-election  # Leader election token
  verbs:
  - get
  - update
- apiGroups:
  - "coordination.k8s.io"
  resources:
  - leases
  verbs:
  - create
- apiGroups:  # To create the leader election token and hpa events
  - ""
  resources:
  - configmaps
  - events
  verbs:
  - create
- nonResourceURLs:
  - "/version"
  - "/healthz"
  verbs:
  - get
- apiGroups:  # to get the kube-system namespace UID and generate a cluster ID
  - ""
  resources:
  - namespaces
  resourceNames:
  - "kube-system"
  verbs:
  - get
- apiGroups:  # To create the cluster-id configmap
  - ""
  resources:
  - configmaps
  resourceNames:
  - "datadog-cluster-id"
  verbs:
  - create
  - get
  - update
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  - persistentvolumeclaims
  - serviceaccounts
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - "apps"
  resources:
  - deployments
  - replicasets
  - daemonsets
  - statefulsets
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - "batch"
  resources:
  - cronjobs
  - jobs
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  - networkpolicies
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - roles
  - rolebindings
  - clusterroles
  - clusterrolebindings
  verbs:
  - list
  - get
  - watch
- apiGroups:
  - autoscaling.k8s.io
  resources:
  - verticalpodautoscalers
  verbs:
  - list
  - get
  - watch
- apiGroups:
    - apiextensions.k8s.io
  resources:
    - customresourcedefinitions
  verbs:
    - list
    - get
    - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  resourceNames:
    - "datadog-webhook"
  verbs: ["get", "list", "watch", "update"]
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  verbs: ["create"]
- apiGroups: ["batch"]
  resources: ["jobs", "cronjobs"]
  verbs: ["get"]
- apiGroups: ["apps"]
  resources: ["statefulsets", "replicasets", "deployments", "daemonsets"]
  verbs: ["get"]
- apiGroups:
  - "security.openshift.io"
  resources:
  - securitycontextconstraints
  verbs:
  - use
  resourceNames:
  - datadog-cluster-agent
  - hostnetwork
---
# Source: datadog/templates/kube-state-metrics-core-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRole
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-ksm-core
rules:
- apiGroups:
  - ""
  resources:
  - secrets
  - configmaps
  - nodes
  - pods
  - services
  - resourcequotas
  - replicationcontrollers
  - limitranges
  - persistentvolumeclaims
  - persistentvolumes
  - namespaces
  - endpoints
  - events
  verbs:
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - statefulsets
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - cronjobs
  - jobs
  verbs:
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - list
  - watch
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  - volumeattachments
  verbs:
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - list
  - watch
- apiGroups:
    - apiextensions.k8s.io
  resources:
    - customresourcedefinitions
  verbs:
    - list
    - watch
---
# Source: datadog/templates/rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRole
metadata:
  name: datadog
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
rules:
- nonResourceURLs:
  - "/metrics"
  - "/metrics/slis"
  verbs:
  - get
- apiGroups:  # Kubelet connectivity
  - ""
  resources:
  - nodes/metrics
  - nodes/spec
  - nodes/proxy
  - nodes/stats
  verbs:
  - get
- apiGroups:  # leader election check
  - ""
  resources:
  - endpoints
  verbs:
  - get
- apiGroups:
  - "security.openshift.io"
  resources:
  - securitycontextconstraints
  verbs:
  - use
  resourceNames:
  - datadog
  - hostaccess
  - privileged
- apiGroups:  # leader election check
  - "coordination.k8s.io"
  resources:
  - leases
  verbs:
  - get
---
# Source: datadog/templates/agent-clusterchecks-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-cluster-checks
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: datadog
subjects:
  - kind: ServiceAccount
    name: datadog-cluster-checks
    namespace: datadog-agent
---
# Source: datadog/templates/cluster-agent-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-cluster-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: datadog-cluster-agent
subjects:
  - kind: ServiceAccount
    name: datadog-cluster-agent
    namespace: datadog-agent
---
# Source: datadog/templates/kube-state-metrics-core-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRoleBinding
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-ksm-core
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: datadog-ksm-core
subjects:
  - kind: ServiceAccount
    name: datadog-cluster-checks
    namespace: datadog-agent
---
# Source: datadog/templates/rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: ClusterRoleBinding
metadata:
  name: datadog
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: datadog
subjects:
  - kind: ServiceAccount
    name: datadog
    namespace: datadog-agent
---
# Source: datadog/templates/cluster-agent-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: Role
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-cluster-agent-main
  namespace: datadog-agent
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get", "list", "watch", "update", "create"]
---
# Source: datadog/templates/dca-helm-values-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: Role
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-dca-flare
  namespace: datadog-agent
rules:
- apiGroups:
  - ""
  resources:
  - secrets
  - configmaps
  verbs:
  - get
  - list
---
# Source: datadog/templates/cluster-agent-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: RoleBinding
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: "datadog-cluster-agent-main"
  namespace: datadog-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: datadog-cluster-agent-main
subjects:
  - kind: ServiceAccount
    name: datadog-cluster-agent
    namespace: datadog-agent
---
# Source: datadog/templates/dca-helm-values-rbac.yaml
apiVersion: "rbac.authorization.k8s.io/v1"
kind: RoleBinding
metadata:
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
  name: datadog-dca-flare
  namespace: datadog-agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: datadog-dca-flare
subjects:
  - kind: ServiceAccount
    name: datadog-cluster-agent
    namespace: datadog-agent
---
# Source: datadog/templates/agent-services.yaml
apiVersion: v1
kind: Service
metadata:
  name: datadog-cluster-agent
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
spec:
  type: ClusterIP
  selector:
    app: datadog-cluster-agent
  ports:
  - port: 5005
    name: agentport
    protocol: TCP
---
# Source: datadog/templates/agent-services.yaml
apiVersion: v1
kind: Service
metadata:
  name: datadog-cluster-agent-admission-controller
  namespace: datadog-agent
  labels:
    app: "datadog"
    chart: "datadog-3.58.2"
    release: "datadog"
    heritage: "Helm"
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
spec:
  selector:
    app: datadog-cluster-agent
  ports:
  - port: 443
    targetPort: 8000
    name: datadog-webhook
    protocol: TCP
---
# Source: datadog/templates/agent-services.yaml
apiVersion: v1
kind: Service

metadata:
  name: datadog
  namespace: datadog-agent
  labels:
    app: "datadog"
    chart: "datadog-3.58.2"
    release: "datadog"
    heritage: "Helm"
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
spec:
  selector:
    app: datadog
  ports:
    - protocol: UDP
      port: 8125
      targetPort: 8125
      name: dogstatsdport
    - protocol: TCP
      port: 8126
      targetPort: 8126
      name: traceport
  internalTrafficPolicy: Local
---
# Source: datadog/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: datadog
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
    app.kubernetes.io/component: agent
    
spec:
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: datadog
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "datadog"
        app.kubernetes.io/instance: "datadog"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: agent
        admission.datadoghq.com/enabled: "false"
        app: datadog
        
      name: datadog
      annotations:
        checksum/clusteragent_token: d1284848a462e5feb13cfbc55a8d3eb48c477b6916832a592867cb5a4a9e4969
        checksum/install_info: 3c5d7a2732f453d72b241f37b74f59319bcbf51e387a8fc35dc47bc4a1a7a390
        checksum/autoconf-config: 74234e98afe7498fb5daf1f36ac2d78acc339464f950703b8c019892f982b90b
        checksum/confd-config: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
        checksum/checksd-config: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        runAsUser: 0
      hostPID: true
      containers:
      - name: agent
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["agent", "run"]
        
        resources:
          {}
        ports:
        - containerPort: 8125
          name: dogstatsdport
          protocol: UDP
        env:
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "true"
          - name: DD_AUTH_TOKEN_FILE_PATH
            value: /etc/datadog-agent/auth/token
          
          - name: KUBERNETES
            value: "yes"
          - name: DD_KUBERNETES_KUBELET_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_OTLP_CONFIG_LOGS_ENABLED
            value: "false"
          
          
          - name: DD_LOG_LEVEL
            value: "INFO"
          - name: DD_DOGSTATSD_PORT
            value: "8125"
          - name: DD_DOGSTATSD_NON_LOCAL_TRAFFIC
            value: "true"
          - name: DD_DOGSTATSD_TAG_CARDINALITY
            value: "low"
          - name: DD_CLUSTER_AGENT_ENABLED
            value: "true"
          - name: DD_CLUSTER_AGENT_KUBERNETES_SERVICE_NAME
            value: datadog-cluster-agent
          - name: DD_CLUSTER_AGENT_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                  name: datadog-cluster-agent
                  key: token
          - name: DD_APM_ENABLED
            value: "true"
          - name: DD_LOGS_ENABLED
            value: "false"
          - name: DD_LOGS_CONFIG_CONTAINER_COLLECT_ALL
            value: "false"
          - name: DD_LOGS_CONFIG_K8S_CONTAINER_USE_FILE
            value: "true"
          - name: DD_LOGS_CONFIG_AUTO_MULTI_LINE_DETECTION
            value: "false"
          - name: DD_HEALTH_PORT
            value: "5555"
          - name: DD_DOGSTATSD_SOCKET
            value: "/var/run/datadog/dsd.socket"
          - name: DD_EXTRA_CONFIG_PROVIDERS
            value: "endpointschecks"
          
          - name: DD_IGNORE_AUTOCONF
            value: "kubernetes_state"
          - name: DD_CONTAINER_LIFECYCLE_ENABLED
            value: "true"
          - name: DD_ORCHESTRATOR_EXPLORER_ENABLED
            value: "true"
          - name: DD_EXPVAR_PORT
            value: "6000"
          - name: DD_COMPLIANCE_CONFIG_ENABLED
            value: "false"
          - name: DD_CONTAINER_IMAGE_ENABLED
            value: "true"        
        volumeMounts:
          - name: logdatadog
            mountPath: /var/log/datadog
            readOnly: false # Need RW to write logs
          - name: installinfo
            subPath: install_info
            mountPath: /etc/datadog-agent/install_info
            readOnly: true
          - name: tmpdir
            mountPath: /tmp
            readOnly: false # Need RW to write to /tmp directory
          
          - name: os-release-file
            mountPath: /host/etc/os-release
            readOnly: true
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: false # Need RW to mount to config path
          - name: auth-token
            mountPath: /etc/datadog-agent/auth
            readOnly: false # Need RW to write auth token
          
          - name: runtimesocketdir
            mountPath: /host/var/run
            mountPropagation: None
            readOnly: true
          
          - name: dsdsocket
            mountPath: /var/run/datadog
            readOnly: false
          - name: procdir
            mountPath: /host/proc
            mountPropagation: None
            readOnly: true
          - name: cgroups
            mountPath: /host/sys/fs/cgroup
            mountPropagation: None
            readOnly: true
        livenessProbe:
          failureThreshold: 6
          httpGet:
            path: /live
            port: 5555
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          failureThreshold: 6
          httpGet:
            path: /ready
            port: 5555
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
      - name: trace-agent
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["trace-agent", "-config=/etc/datadog-agent/datadog.yaml"]  
        resources:
          {}
        ports:
        - containerPort: 8126
          name: traceport
          protocol: TCP
        env:
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "true"
          - name: DD_AUTH_TOKEN_FILE_PATH
            value: /etc/datadog-agent/auth/token
          
          - name: KUBERNETES
            value: "yes"
          - name: DD_KUBERNETES_KUBELET_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_OTLP_CONFIG_LOGS_ENABLED
            value: "false"
          
          - name: DD_CLUSTER_AGENT_ENABLED
            value: "true"
          - name: DD_CLUSTER_AGENT_KUBERNETES_SERVICE_NAME
            value: datadog-cluster-agent
          - name: DD_CLUSTER_AGENT_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                  name: datadog-cluster-agent
                  key: token
          
          - name: DD_LOG_LEVEL
            value: "INFO"
          - name: DD_APM_ENABLED
            value: "true"
          - name: DD_APM_NON_LOCAL_TRAFFIC
            value: "true"
          - name: DD_APM_RECEIVER_PORT
            value: "8126"
          - name: DD_APM_RECEIVER_SOCKET
            value: "/var/run/datadog/apm.socket"
          - name: DD_DOGSTATSD_SOCKET
            value: "/var/run/datadog/dsd.socket"
          - name: DD_INSTRUMENTATION_INSTALL_TIME
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_time
          - name: DD_INSTRUMENTATION_INSTALL_ID
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_id
          - name: DD_INSTRUMENTATION_INSTALL_TYPE
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_type        
        volumeMounts:
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: true
          - name: logdatadog
            mountPath: /var/log/datadog
            readOnly: false # Need RW to write logs
          - name: auth-token
            mountPath: /etc/datadog-agent/auth
            readOnly: true
          - name: procdir
            mountPath: /host/proc
            mountPropagation: None
            readOnly: true
          - name: cgroups
            mountPath: /host/sys/fs/cgroup
            mountPropagation: None
            readOnly: true
          - name: tmpdir
            mountPath: /tmp
            readOnly: false # Need RW for tmp directory
          - name: dsdsocket
            mountPath: /var/run/datadog
            readOnly: false # Need RW for UDS DSD socket
          
          - name: runtimesocketdir
            mountPath: /host/var/run
            mountPropagation: None
            readOnly: true
          
        livenessProbe:
          initialDelaySeconds: 15
          periodSeconds: 15
          tcpSocket:
            port: 8126
          timeoutSeconds: 5
      - name: process-agent
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["process-agent", "--cfgpath=/etc/datadog-agent/datadog.yaml"]  
        resources:
          {}
        env:
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "true"
          - name: DD_AUTH_TOKEN_FILE_PATH
            value: /etc/datadog-agent/auth/token
          
          - name: KUBERNETES
            value: "yes"
          - name: DD_KUBERNETES_KUBELET_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_OTLP_CONFIG_LOGS_ENABLED
            value: "false"
          
          - name: DD_CLUSTER_AGENT_ENABLED
            value: "true"
          - name: DD_CLUSTER_AGENT_KUBERNETES_SERVICE_NAME
            value: datadog-cluster-agent
          - name: DD_CLUSTER_AGENT_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                  name: datadog-cluster-agent
                  key: token
          
          - name: DD_PROCESS_AGENT_DISCOVERY_ENABLED
            value: "true"
          - name: DD_LOG_LEVEL
            value: "INFO"
          - name: DD_SYSTEM_PROBE_ENABLED
            value: "false"
          - name: DD_DOGSTATSD_SOCKET
            value: "/var/run/datadog/dsd.socket"
          - name: DD_ORCHESTRATOR_EXPLORER_ENABLED
            value: "true"        
        volumeMounts:
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: true
          - name: logdatadog
            mountPath: /var/log/datadog
            readOnly: false # Need RW to write logs
          - name: auth-token
            mountPath: /etc/datadog-agent/auth
            readOnly: true
          - name: dsdsocket
            mountPath: /var/run/datadog
            readOnly: false # Need RW for UDS DSD socket
          - name: tmpdir
            mountPath: /tmp
            readOnly: false # Need RW to write to tmp directory
          
          - name: os-release-file
            mountPath: /host/etc/os-release
            readOnly: true
          
          - name: runtimesocketdir
            mountPath: /host/var/run
            mountPropagation: None
            readOnly: true
          
          - name: cgroups
            mountPath: /host/sys/fs/cgroup
            mountPropagation: None
            readOnly: true
          - name: passwd
            mountPath: /etc/passwd
            readOnly: true
          - name: procdir
            mountPath: /host/proc
            mountPropagation: None
            readOnly: true
      initContainers:
          
      - name: init-volume
        
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["bash", "-c"]
        args:
          - cp -r /etc/datadog-agent /opt
        volumeMounts:
          - name: config
            mountPath: /opt/datadog-agent
            readOnly: false # Need RW for config path
        resources:
          {}
      - name: init-config
        
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command:
          - bash
          - -c
        args:
          - for script in $(find /etc/cont-init.d/ -type f -name '*.sh' | sort) ; do bash $script ; done
        volumeMounts:
          - name: logdatadog
            mountPath: /var/log/datadog
            readOnly: false # Need RW to write logs
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: false # Need RW for config path
          - name: procdir
            mountPath: /host/proc
            mountPropagation: None
            readOnly: true
          
          - name: runtimesocketdir
            mountPath: /host/var/run
            mountPropagation: None
            readOnly: true
        env:
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "true"
          - name: DD_AUTH_TOKEN_FILE_PATH
            value: /etc/datadog-agent/auth/token
          
          - name: KUBERNETES
            value: "yes"
          - name: DD_KUBERNETES_KUBELET_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: DD_OTLP_CONFIG_LOGS_ENABLED
            value: "false"
          
        resources:
          {}
      volumes:
      - name: auth-token
        emptyDir: {}
      - name: installinfo
        configMap:
          name: datadog-installinfo
      - name: config
        emptyDir: {}
        
      - name: logdatadog
        emptyDir: {}
      - name: tmpdir
        emptyDir: {}
      - hostPath:
          path: /proc
        name: procdir
      - hostPath:
          path: /sys/fs/cgroup
        name: cgroups
      - hostPath:
          path: /etc/os-release
        name: os-release-file
      - hostPath:
          path: /var/run/datadog/
          type: DirectoryOrCreate
        name: dsdsocket
      - hostPath:
          path: /var/run/datadog/
          type: DirectoryOrCreate
        name: apmsocket
      - name: s6-run
        emptyDir: {}
      - hostPath:
          path: /etc/passwd
        name: passwd
      - hostPath:
          path: /var/run
        name: runtimesocketdir
      tolerations:
      affinity:
        {}
      serviceAccountName: "datadog"
      automountServiceAccountToken: true
      nodeSelector:
        kubernetes.io/os: linux
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 10%
    type: RollingUpdate
---
# Source: datadog/templates/agent-clusterchecks-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datadog-clusterchecks
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
    app.kubernetes.io/component: clusterchecks-agent
    
spec:
  replicas: 2
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: datadog-clusterchecks
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "datadog"
        app.kubernetes.io/instance: "datadog"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: clusterchecks-agent
        admission.datadoghq.com/enabled: "false"
        app: datadog-clusterchecks
        
      name: datadog-clusterchecks
      annotations:
        checksum/clusteragent_token: d56cd35d2ed589e9817382c6d02cf18a1d24772863e156f83e78a038ee24b51d
        checksum/install_info: 3c5d7a2732f453d72b241f37b74f59319bcbf51e387a8fc35dc47bc4a1a7a390
    spec:
      serviceAccountName: datadog-cluster-checks
      automountServiceAccountToken: true
      imagePullSecrets:
        []
      initContainers:
      - name: init-volume
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["bash", "-c"]
        args:
          - cp -r /etc/datadog-agent /opt
        volumeMounts:
          - name: config
            mountPath: /opt/datadog-agent
            readOnly: false # Need RW for writing agent config files
        resources:
          {}
      - name: init-config
        image: "gcr.io/datadoghq/agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command: ["bash", "-c"]
        args:
          - for script in $(find /etc/cont-init.d/ -type f -name '*.sh' | sort) ; do bash $script ; done
        volumeMounts:
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: false # Need RW for writing datadog.yaml config file
        resources:
          {}
      containers:
      - name: agent
        image: "gcr.io/datadoghq/agent:7.51.0"
        command: ["bash", "-c"]
        args:
          - rm -rf /etc/datadog-agent/conf.d && touch /etc/datadog-agent/datadog.yaml && exec agent run
        imagePullPolicy: IfNotPresent
        env:
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
          - name: KUBERNETES
            value: "yes"
          - name: DD_LOG_LEVEL
            value: "INFO"
          - name: DD_EXTRA_CONFIG_PROVIDERS
            value: "clusterchecks"
          - name: DD_HEALTH_PORT
            value: "5557"
          # Cluster checks (cluster-agent communication)
          - name: DD_CLUSTER_AGENT_ENABLED
            value: "true"
          - name: DD_CLUSTER_AGENT_KUBERNETES_SERVICE_NAME
            value: datadog-cluster-agent
          - name: DD_CLUSTER_AGENT_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                  name: datadog-cluster-agent
                  key: token
          # Safely run alongside the daemonset
          - name: DD_ENABLE_METADATA_COLLECTION
            value: "false"
          # Expose CLC stats
          - name: DD_CLC_RUNNER_ENABLED
            value: "true"
          - name: DD_CLC_RUNNER_HOST
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: DD_CLC_RUNNER_ID
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          # Remove unused features
          - name: DD_USE_DOGSTATSD
            value: "false"
          - name: DD_PROCESS_AGENT_ENABLED
            value: "false"
          - name: DD_LOGS_ENABLED
            value: "false"
          - name: DD_APM_ENABLED
            value: "false"
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "false"
          - name: DD_HOSTNAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          
                              
        resources:
          {}
        volumeMounts:
          - name: installinfo
            subPath: install_info
            mountPath: /etc/datadog-agent/install_info
            readOnly: true
          - name: config
            mountPath: /etc/datadog-agent
            readOnly: false # Need RW for config path
        livenessProbe:
          failureThreshold: 6
          httpGet:
            path: /live
            port: 5557
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          failureThreshold: 6
          httpGet:
            path: /ready
            port: 5557
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
      volumes:
        - name: installinfo
          configMap:
            name: datadog-installinfo
        - name: config
          emptyDir: {}
      affinity:
        # Prefer scheduling the runners on different nodes if possible
        # for better checks stability in case of node failure.
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: datadog-clusterchecks
              topologyKey: kubernetes.io/hostname
      nodeSelector:
        kubernetes.io/os: linux
---
# Source: datadog/templates/cluster-agent-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: datadog-cluster-agent
  namespace: datadog-agent
  labels:
    helm.sh/chart: 'datadog-3.58.2'
    app.kubernetes.io/name: "datadog"
    app.kubernetes.io/instance: "datadog"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "7"
    app.kubernetes.io/component: cluster-agent
    
spec:
  replicas: 1
  revisionHistoryLimit: 10
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: datadog-cluster-agent
  template:
    metadata:
      labels:
        app.kubernetes.io/name: "datadog"
        app.kubernetes.io/instance: "datadog"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: cluster-agent
        admission.datadoghq.com/enabled: "false"
        app: datadog-cluster-agent
        
      name: datadog-cluster-agent
      annotations:
        checksum/clusteragent_token: 9f86485d7f07627ccbd29f3ad3996ceb1fa57403f055c1b15e7c6919f944a2c1
        checksum/clusteragent-configmap: 4bd988547c8c6cc1f177d466bee234b3d51f96bd8f1177244bd0cca5cdea8082
        checksum/install_info: 3c5d7a2732f453d72b241f37b74f59319bcbf51e387a8fc35dc47bc4a1a7a390
    spec:
      serviceAccountName: datadog-cluster-agent
      automountServiceAccountToken: true
      initContainers:
      - name: init-volume
        image: "gcr.io/datadoghq/cluster-agent:7.51.0"
        imagePullPolicy: IfNotPresent
        command:
          - cp
          - -r
        args:
          - /etc/datadog-agent
          - /opt
        volumeMounts:
          - name: config
            mountPath: /opt/datadog-agent
      containers:
      - name: cluster-agent
        image: "gcr.io/datadoghq/cluster-agent:7.51.0"
        imagePullPolicy: IfNotPresent
        resources:
          {}
        ports:
        - containerPort: 5005
          name: agentport
          protocol: TCP
        - containerPort: 5000
          name: agentmetrics
          protocol: TCP
        - containerPort: 8000
          name: datadog-webhook
          protocol: TCP
        env:
          - name: DD_POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: DD_HEALTH_PORT
            value: "5556"
          - name: DD_API_KEY
            valueFrom:
              secretKeyRef:
                name: "datadog-secret"
                key: api-key
                optional: true
          
          - name: KUBERNETES
            value: "yes"
          - name: DD_ADMISSION_CONTROLLER_ENABLED
            value: "true"
          - name: DD_ADMISSION_CONTROLLER_WEBHOOK_NAME
            value: "datadog-webhook"
          - name: DD_ADMISSION_CONTROLLER_MUTATE_UNLABELLED
            value: "false"
          - name: DD_ADMISSION_CONTROLLER_SERVICE_NAME
            value: datadog-cluster-agent-admission-controller
          - name: DD_ADMISSION_CONTROLLER_INJECT_CONFIG_MODE
            value: socket
          - name: DD_ADMISSION_CONTROLLER_INJECT_CONFIG_LOCAL_SERVICE_NAME
            value: datadog
          - name: DD_ADMISSION_CONTROLLER_FAILURE_POLICY
            value: "Ignore"
          - name: DD_ADMISSION_CONTROLLER_PORT
            value: "8000"
          
          
          - name: DD_REMOTE_CONFIGURATION_ENABLED
            value: "false"
          - name: DD_CLUSTER_CHECKS_ENABLED
            value: "true"
          - name: DD_EXTRA_CONFIG_PROVIDERS
            value: "kube_endpoints kube_services"
          - name: DD_EXTRA_LISTENERS
            value: "kube_endpoints kube_services"
          - name: DD_LOG_LEVEL
            value: "INFO"
          - name: DD_LEADER_ELECTION
            value: "true"
          - name: DD_LEADER_ELECTION_DEFAULT_RESOURCE
            value: "configmap"
          - name: DD_LEADER_LEASE_DURATION
            value: "15"
          - name: DD_LEADER_LEASE_NAME
            value: datadog-leader-election
          - name: DD_CLUSTER_AGENT_TOKEN_NAME
            value: datadogtoken
          - name: DD_COLLECT_KUBERNETES_EVENTS
            value: "true"
          - name: DD_CLUSTER_AGENT_KUBERNETES_SERVICE_NAME
            value: datadog-cluster-agent
          - name: DD_CLUSTER_AGENT_AUTH_TOKEN
            valueFrom:
              secretKeyRef:
                name: datadog-cluster-agent
                key: token
          - name: DD_CLUSTER_AGENT_COLLECT_KUBERNETES_TAGS
            value: "false"
          - name: DD_KUBE_RESOURCES_NAMESPACE
            value: datadog-agent
          - name: CHART_RELEASE_NAME
            value: "datadog"
          - name: AGENT_DAEMONSET
            value: datadog
          - name: CLUSTER_AGENT_DEPLOYMENT
            value: datadog-cluster-agent
          - name: DD_ORCHESTRATOR_EXPLORER_ENABLED
            value: "true"
          - name: DD_ORCHESTRATOR_EXPLORER_CONTAINER_SCRUBBING_ENABLED
            value: "true"
          - name: DD_INSTRUMENTATION_INSTALL_TIME
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_time
          - name: DD_INSTRUMENTATION_INSTALL_ID
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_id
          - name: DD_INSTRUMENTATION_INSTALL_TYPE
            valueFrom:
              configMapKeyRef:
                name: datadog-kpi-telemetry-configmap
                key: install_type
                              
        livenessProbe:
          failureThreshold: 6
          httpGet:
            path: /live
            port: 5556
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
        readinessProbe:
          failureThreshold: 6
          httpGet:
            path: /ready
            port: 5556
            scheme: HTTP
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 1
          timeoutSeconds: 5
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        volumeMounts:
          - name: datadogrun
            mountPath: /opt/datadog-agent/run
            readOnly: false
          - name: varlog
            mountPath: /var/log/datadog
            readOnly: false
          - name: tmpdir
            mountPath: /tmp
            readOnly: false
          - name: installinfo
            subPath: install_info
            mountPath: /etc/datadog-agent/install_info
            readOnly: true
          - name: confd
            mountPath: /conf.d
            readOnly: true
          - name: config
            mountPath: /etc/datadog-agent
      volumes:
        - name: datadogrun
          emptyDir: {}
        - name: varlog
          emptyDir: {}
        - name: tmpdir
          emptyDir: {}
        - name: installinfo
          configMap:
            name: datadog-installinfo
        - name: confd
          configMap:
            name: datadog-cluster-agent-confd
            items:
            - key: kubernetes_state_core.yaml.default
              path: kubernetes_state_core.yaml.default
        - name: config
          emptyDir: {}
      affinity:
        # Prefer scheduling the cluster agents on different nodes
        # to guarantee that the standby instance can immediately take the lead from a leader running of a faulty node.
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 50
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: datadog-cluster-agent
              topologyKey: kubernetes.io/hostname
      nodeSelector:
        kubernetes.io/os: linux